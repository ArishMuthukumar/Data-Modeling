{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "0JlBZ26SALVN"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "import numpy as np\n",
        "import cupy as cp\n",
        "import time\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate 100,000 random 3D points\n",
        "n_points = 100000\n",
        "np.random.seed(42)\n",
        "points_cpu = np.random.uniform(0, 100, size=(n_points, 3))"
      ],
      "metadata": {
        "id": "IGGJOJ0RAYEG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if CUDA is available and transfer to GPU only if available\n",
        "try:\n",
        "    import cupy as cp\n",
        "    cuda_available = True\n",
        "    print(\"CUDA is available. Using GPU for computation.\")\n",
        "except (ImportError, Exception) as e:\n",
        "    cuda_available = False\n",
        "    print(f\"CUDA is not available: {str(e)}\")\n",
        "    print(\"Falling back to CPU-only computation for GPU tasks.\")\n",
        "\n",
        "print(\"Generated 100,000 3D points in range [0, 100]\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2xpRYnvUAcix",
        "outputId": "2ddeacdb-9eb8-417d-f47b-517b33784aa0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available. Using GPU for computation.\n",
            "Generated 100,000 3D points in range [0, 100]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#CPU-based pairwise Euclidean distance (batched timing)\n",
        "def time_distances_cpu(points, batch_size=1000):\n",
        "    n = points.shape[0]\n",
        "    print(\"\\nCalculating distance matrix in batches on CPU (timing only)...\")\n",
        "    start_time = time.time()\n",
        "    for i in tqdm(range(0, n, batch_size), desc=\"CPU Batches\"):\n",
        "        end_i = min(i + batch_size, n)\n",
        "        points_batch_i = points[i:end_i]\n",
        "        X_batch_i_squared_sum = np.sum(points_batch_i**2, axis=1)\n",
        "        for j in range(0, n, batch_size):\n",
        "            end_j = min(j + batch_size, n)\n",
        "            points_batch_j = points[j:end_j]\n",
        "            X_batch_j_squared_sum = np.sum(points_batch_j**2, axis=1)\n",
        "\n",
        "            dot_product_batch = points_batch_i @ points_batch_j.T\n",
        "\n",
        "            # Calculate distance matrix for the current batch - result is not stored\n",
        "            dist_matrix_batch = np.sqrt(np.maximum(\n",
        "                X_batch_i_squared_sum[:, np.newaxis] + X_batch_j_squared_sum[np.newaxis, :] - 2 * dot_product_batch,\n",
        "                0.0\n",
        "            ))\n",
        "    end_time = time.time()\n",
        "    return end_time - start_time"
      ],
      "metadata": {
        "id": "SrVM0b8fAlin"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GPU-based pairwise Euclidean distance (batched timing)\n",
        "def time_distances_gpu(points_cpu, batch_size=1000):\n",
        "    n = points_cpu.shape[0]\n",
        "    if not cuda_available:\n",
        "        print(\"GPU computation skipped due to CUDA unavailability.\")\n",
        "        return None\n",
        "\n",
        "    print(\"\\nCalculating distance matrix in batches on GPU (timing only)...\")\n",
        "    start_time = time.time()\n",
        "    try:\n",
        "        for i in tqdm(range(0, n, batch_size), desc=\"GPU Batches\"):\n",
        "            end_i = min(i + batch_size, n)\n",
        "            points_batch_i_cpu = points_cpu[i:end_i]\n",
        "            points_batch_i_gpu = cp.asarray(points_batch_i_cpu) # Transfer batch to GPU\n",
        "\n",
        "            X_batch_i_squared_sum_gpu = cp.sum(points_batch_i_gpu**2, axis=1)\n",
        "\n",
        "            for j in range(0, n, batch_size):\n",
        "                end_j = min(j + batch_size, n)\n",
        "                points_batch_j_cpu = points_cpu[j:end_j]\n",
        "                points_batch_j_gpu = cp.asarray(points_batch_j_cpu) # Transfer batch to GPU\n",
        "\n",
        "                dot_product_batch_gpu = points_batch_i_gpu @ points_batch_j_gpu.T\n",
        "\n",
        "                # Calculate distance matrix for the current batch - result is not stored\n",
        "                dist_matrix_batch_gpu = cp.sqrt(cp.maximum(\n",
        "                    X_batch_i_squared_sum_gpu[:, cp.newaxis] + cp.sum(points_batch_j_gpu**2, axis=1)[cp.newaxis, :] - 2 * dot_product_batch_gpu,\n",
        "                    0.0\n",
        "                ))\n",
        "            # Ensure all GPU operations for this row batch are complete\n",
        "            cp.cuda.Device(0).synchronize()\n",
        "    except Exception as e:\n",
        "        print(f\"Error during GPU computation: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "    end_time = time.time()\n",
        "    return end_time - start_time"
      ],
      "metadata": {
        "id": "-5hLR1snAtTg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Timing CPU & GPU\n",
        "cpu_time = time_distances_cpu(points_cpu, batch_size=1000)\n",
        "if cpu_time is not None:\n",
        "    print(f\"Batch-wise CPU Time: {cpu_time:.2f} seconds\")\n",
        "\n",
        "gpu_time = time_distances_gpu(points_cpu, batch_size=1000)\n",
        "if gpu_time is not None:\n",
        "    print(f\"\\n Batch-wise GPU Time: {gpu_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyMvaDkJA1gS",
        "outputId": "6fabccc2-97a2-49f9-8cc3-5933ba8da6ec"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Calculating distance matrix in batches on CPU (timing only)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "CPU Batches: 100%|██████████| 100/100 [01:52<00:00,  1.13s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Batch-wise CPU Time: 112.57 seconds\n",
            "\n",
            "Calculating distance matrix in batches on GPU (timing only)...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "GPU Batches: 100%|██████████| 100/100 [00:07<00:00, 13.40it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Batch-wise GPU Time: 7.47 seconds\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Compare execution times\n",
        "if cpu_time is not None and gpu_time is not None:\n",
        "    print(\"\\n--- Performance Comparison ---\")\n",
        "    print(f\"Batch-wise CPU Execution Time: {cpu_time:.2f} seconds\")\n",
        "    print(f\"Batch-wise GPU Execution Time: {gpu_time:.2f} seconds\")\n",
        "    if gpu_time > 0:\n",
        "        speedup = cpu_time / gpu_time\n",
        "        print(f\"Speedup: {speedup:.2f}x (GPU over CPU)\")\n",
        "    else:\n",
        "        print(\"Speedup cannot be calculated as GPU time is zero.\")\n",
        "elif cpu_time is not None:\n",
        "    print(\"--- Performance Comparison ---\")\n",
        "    print(f\"Batch-wise CPU Execution Time: {cpu_time:.2f} seconds\")\n",
        "    print(\"GPU computation was skipped or failed, cannot compare performance.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZbfx4NhBFf_",
        "outputId": "588913ca-8e3b-40dc-806f-a27f9d087709"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Performance Comparison ---\n",
            "Batch-wise CPU Execution Time: 112.57 seconds\n",
            "Batch-wise GPU Execution Time: 7.47 seconds\n",
            "Speedup: 15.08x (GPU over CPU)\n"
          ]
        }
      ]
    }
  ]
}